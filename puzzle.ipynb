{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. All the clue functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words in titles of popular movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1432,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this isn't super scalable, but these clues are fun and they come up surprisingly often\n",
    "\n",
    "def movie_clue(word, wordlist='moviewords.txt', clues='movieclues.txt'):\n",
    "    from nltk.tokenize import word_tokenize    \n",
    "    \n",
    "    with open(wordlist, 'r') as g:    \n",
    "        words = set(g.read().split('\\n'))\n",
    "            \n",
    "    if word not in words:\n",
    "        return False\n",
    "    \n",
    "    word = word[0].upper() + word[1:]\n",
    "    \n",
    "    with open(clues, 'r') as g:\n",
    "        clues = g.read().split('\\n')\n",
    "        \n",
    "    for clue in clues:\n",
    "        if word in word_tokenize(clue):\n",
    "            return clue.replace(word, '__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"The __ of the Rings: The Return of the King\" (2003 movie)'"
      ]
     },
     "execution_count": 1433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_clue('lord')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idioms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1438,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# like movies, this isn't super scalable, but these clues are fun and they come up surprisingly often\n",
    "\n",
    "def idiom_clue(word, idioms='idioms.txt'):\n",
    "    with open(idioms, 'r') as g:\n",
    "        idioms = g.read().split('\\n')\n",
    "    \n",
    "    for idiom in idioms:\n",
    "        if word in idiom.split():\n",
    "            clue = idiom.replace(word, '__')\n",
    "            return clue[0].upper() + clue[1:]\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Whole __ yards'"
      ]
     },
     "execution_count": 1439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idiom_clue('nine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# definitions for 1000 popular words (scraped from the internet)\n",
    "\n",
    "def describe(word, file='definitions.txt'):\n",
    "    with open(file, 'r') as g:\n",
    "        defs = g.read().split('\\n')\n",
    "            \n",
    "    for ind,x in enumerate(defs):\n",
    "        if word == x.split(': ')[0]:\n",
    "            clue = defs[ind].split(': ')[1]\n",
    "            return clue[0].upper() + clue[1:]\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An elaborate song for solo voice'"
      ]
     },
     "execution_count": 1441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe('aria')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1442,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from the NYT\n",
    "\n",
    "def find_seq(word, file='seq_2words_0sw.pkl'):\n",
    "    \n",
    "    import pickle\n",
    "    with open(file, 'rb') as g:\n",
    "        phrases = pickle.load(g)\n",
    "            \n",
    "    lower = word.lower()\n",
    "    upper = word[0].upper() + word[1:]\n",
    "    \n",
    "    # it should be a fairly common phrase\n",
    "    for phrase in phrases:\n",
    "        if phrase[1] < 400:\n",
    "            break\n",
    "            \n",
    "        if lower in phrase[0] or upper in phrase[0]:\n",
    "            clue = phrase[0]\n",
    "#             print(phrase[1])\n",
    "\n",
    "            for word in clue:\n",
    "                if word[0].isupper():\n",
    "                    return ' '.join([i[0].upper() + i[1:] for i in clue]).replace(lower, '___').replace(upper, '___')\n",
    "            clue = ' '.join(clue).replace(lower, '___').replace(upper, '___')\n",
    "            \n",
    "            return clue[0].upper() + clue[1:]\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'President ___'"
      ]
     },
     "execution_count": 1443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_seq('Obama')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word pairs that share a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# these kinds of clues are fun, although it's hard to generate reliably good instances\n",
    "\n",
    "def find_xyz(word, file='seq_2words_0sw.pkl', freqs='wordfreqs.pkl'):\n",
    "    \n",
    "    import pickle\n",
    "    with open(file, 'rb') as g:\n",
    "        phrases = pickle.load(g)\n",
    "        \n",
    "    with open(freqs, 'rb') as g:\n",
    "        freqs = pickle.load(g)\n",
    "\n",
    "    answer = []\n",
    "    \n",
    "    lower = word.lower()\n",
    "    upper = word[0].upper() + word[1:]\n",
    "\n",
    "    swords = set(['would', 'could', 'should', 'I’ve', 'he’s', 'she’s', \"I've\", \"he's\", \"she's\"])\n",
    "    \n",
    "    for phrase in phrases:\n",
    "        if phrase[1] < 10: # change this number to vary results\n",
    "            continue\n",
    "        if phrase[0][0] in swords or phrase[0][1] in swords:\n",
    "            continue\n",
    "        if '“' in phrase[0][0] or '“' in phrase[0][1] or '\"' in phrase[0][0] or '\"' in phrase[0][1]:\n",
    "            continue\n",
    "        if lower in phrase[0] or upper in phrase[0]:\n",
    "            other = ' '.join([x for x in phrase[0] if (x != lower and x != upper)])\n",
    "            answer.append(other)\n",
    "            if len(answer)==2:\n",
    "                try:\n",
    "                    # the model I refer to is my word2vec model\n",
    "                    if model.similarity(answer[0], answer[1]) < .4: # this is also a good number to play with\n",
    "                        return 'Word with \"%s\" or \"%s\"' % (answer[0], answer[1])\n",
    "                except:\n",
    "                    return 'Word with \"%s\" or \"%s\"' % (answer[0], answer[1])\n",
    "                answer.pop()\n",
    "\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Word with \"gold\" or \"fig\"'"
      ]
     },
     "execution_count": 1455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_xyz('leaf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNet synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def synset(word, model=model):\n",
    "    from nltk.corpus import wordnet as wn\n",
    "    \n",
    "    syns = []\n",
    "\n",
    "    try:\n",
    "        for x in wn.synsets(word):\n",
    "            for y in x.lemmas():\n",
    "                syns.append(y.name())\n",
    "        \n",
    "        syn = []\n",
    "        \n",
    "        for ind,j in enumerate(syns):\n",
    "            if word[:2] in j or word[0].upper()+word[1:] in j:\n",
    "                continue\n",
    "            try:\n",
    "                if model.similarity(word, j) > 0.4:\n",
    "                    syn.append(j)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    if len(syn) > 0:\n",
    "        syn = syn[0].replace('_', ' ')\n",
    "        return syn[0].upper() + syn[1:]\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Canis familiaris'"
      ]
     },
     "execution_count": 1460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset('dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is pretty neat: WordNet knows category relationships between words\n",
    "\n",
    "def example(word, freqs='wordfreqs.pkl'):\n",
    "    from nltk.corpus import wordnet as wn\n",
    "    \n",
    "    import pickle\n",
    "    with open(freqs, 'rb') as g:\n",
    "        freqs = pickle.load(g)\n",
    "        \n",
    "    if freqs[word] < 100:\n",
    "        return False\n",
    "         \n",
    "    ex_d = 1\n",
    "    ex_u = 1\n",
    "    try:\n",
    "        syn = wn.synset('%s.n.01' % word)\n",
    "    except:\n",
    "        return False\n",
    "        \n",
    "    # examples of the word (i.e., down a category layer)\n",
    "    try:\n",
    "        ex_down = [x.name().split('.')[0] for x in syn.hyponyms() if '_' not in x.name().split('.')[0] and word[:3] not in x.name().split('.')[0]][0]\n",
    "    except:\n",
    "        ex_d = 0\n",
    "    \n",
    "    # what the word is an example of (i.e., up a category layer)\n",
    "    try:\n",
    "        ex_up = [x.name().split('.')[0] for x in syn.hypernyms() if '_' not in x.name().split('.')[0] and word[:3] not in x.name().split('.')[0]][0]\n",
    "    except:\n",
    "        ex_u = 0\n",
    "    \n",
    "    # figure out which direction to return\n",
    "    if ex_d == 0 and ex_u == 0:\n",
    "        return False\n",
    "    elif ex_d == 0 and ex_u == 1:\n",
    "        return 'Type of ' + ex_up\n",
    "    elif ex_d == 1 and ex_u == 0:\n",
    "        return ex_down[0].upper() + ex_down[1:] + ', for one'\n",
    "\n",
    "    try:\n",
    "        if model.similarity(ex_up, word) > .4:\n",
    "            return 'Type of ' + ex_up\n",
    "    except:\n",
    "        try:\n",
    "            if model.similarity(ex_down, word) > .4:\n",
    "                return ex_down[0].upper() + ex_down[1:] + ', for one'\n",
    "        except: pass\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Type of canine'"
      ]
     },
     "execution_count": 1465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example('dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### word2vec synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word2vec is fun to play around with, but it can take a long time to train a model\n",
    "\n",
    "import nltk\n",
    "import gensim\n",
    "import os\n",
    "\n",
    "nltk_path = os.sep.join([os.environ['HOME'], 'nltk_data'])\n",
    "google_vec_file = '~/GoogleNews-vectors-negative300.bin.gz'\n",
    "\n",
    "nltk.data.path.insert(0, nltk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(google_vec_file, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open('word-file', 'r') as g:\n",
    "#     words = g.read()\n",
    "    \n",
    "# words = set(words.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def synonyms(answer, words='word-file'):\n",
    "    \n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    with open('word-file', 'r') as g:\n",
    "        words = g.read()\n",
    "    \n",
    "    words = set(words.split('\\n'))\n",
    "\n",
    "    similars = model.most_similar(answer)\n",
    "    \n",
    "    clue = [x[0] for x in similars if (\n",
    "        x[0] in words and \n",
    "        answer[:2] not in x[0][:2] and \n",
    "        x[1]>0.53 and\n",
    "        ps.stem(x[0]) != ps.stem(answer)\n",
    "    )]\n",
    "\n",
    "    for ind,i in enumerate(clue):\n",
    "        if (i[:2] in [x[:2] for x in clue[:ind]] or\n",
    "           ps.stem(i) in [ps.stem(x) for x in clue[:ind]]):\n",
    "            clue.pop(ind)\n",
    "            \n",
    "    clue = clue[:2]\n",
    "    \n",
    "    try:\n",
    "        if model.most_similar(positive=clue, topn=1)[0][0] != answer:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    clue = ' or '.join(clue[:2])\n",
    "\n",
    "    if len(clue) < 2:\n",
    "        return False\n",
    "\n",
    "    return 'Like ' + clue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Like spooky or freaky'"
      ]
     },
     "execution_count": 1469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms('creepy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNet definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def define(word):\n",
    "    import re\n",
    "    import inflect\n",
    "    p = inflect.engine()\n",
    "    from textblob import TextBlob\n",
    "    from textblob import Word\n",
    "    \n",
    "    from nltk.corpus import wordnet\n",
    "    try:\n",
    "        defin = wordnet.synsets(word)[0].definition().split('; ')\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    if word[:3] not in min(defin):\n",
    "        defin = min(defin)\n",
    "        defin = re.sub(r'\\([^)]*\\)', '', defin)\n",
    "        defin = defin.replace('  ', ' ')\n",
    "        if defin[0] == ' ':\n",
    "            defin = defin[1:]\n",
    "        if defin[-1:] == ' ':\n",
    "            defin = defin[:-1]\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    if TextBlob(defin[0]).tags[0][1] == 'DT':\n",
    "        defin = ' '.join(defin.split()[1:])\n",
    "#         print(defin)\n",
    "    \n",
    "    \n",
    "    # NOTE: this is a very crude way to correctly pluralize a description\n",
    "    # however, it's more fun than just adding \"(plural)\" to clues\n",
    "    # verb tense isn't always correct, either\n",
    "    if word[-1:] == 's':\n",
    "        \n",
    "        singulars = ['A', 'a', 'An', 'an', 'The', 'the']\n",
    "        pluralclue = []\n",
    "        first = 0\n",
    "        \n",
    "#         print(defin)\n",
    "                \n",
    "        for ind,(w, pos) in enumerate(TextBlob(defin).tags):\n",
    "            if (first == 0 and\n",
    "                    ('NN' in pos or ('VB' in pos and \n",
    "                        TextBlob(defin).tags[ind-1][1] != 'TO' and \n",
    "                        w[-1:] != 'd')) and \n",
    "                    (ind == len(defin.split())-1 or 'NN' not in TextBlob(defin).tags[ind+1][1]) and\n",
    "                    #(ind >= len(defin.split())-3 or 'NN' not in TextBlob(defin).tags[ind+3][1]) and \n",
    "                    ('ing' not in w and TextBlob(defin).tags[ind-1][0] != 'for')):\n",
    "                if w[-1:] != 's':\n",
    "                    pluralclue.append(p.plural(w))\n",
    "                else:\n",
    "                    pluralclue.append(w)\n",
    "#                 print(pos, p.plural(w))\n",
    "                first = 1\n",
    "            else:                \n",
    "                if (('NN' in pos or ('VB' in pos and w[-1:] != 'd' and \n",
    "                            TextBlob(defin).tags[ind-1][1] != 'TO' and\n",
    "                            TextBlob(defin).tags[ind-3][1] != 'TO')) and\n",
    "                        (ind == len(defin.split())-1 or 'NN' not in TextBlob(defin).tags[ind+1][1]) and\n",
    "                        #(ind >= len(defin.split())-3 or 'NN' not in TextBlob(defin).tags[ind+3][1]) and \n",
    "                        w != 'been' and\n",
    "                        not ('ing' in w and TextBlob(defin).tags[ind-1][0] != 'for')):\n",
    "                    if w[-1:] != 's':\n",
    "                        pluralclue.append(p.plural(w))\n",
    "                    else:\n",
    "                        pluralclue.append(w)\n",
    "#                     print(pos, p.plural(w))\n",
    "                    first = 1\n",
    "                else:\n",
    "                    pluralclue.append(w)\n",
    "#                     print(pos, w)\n",
    "        pluralclue = [x for x in pluralclue if x not in singulars]\n",
    "        pluralclue = ' '.join(pluralclue)\n",
    "        return pluralclue[0].upper() + pluralclue[1:]\n",
    "    else:\n",
    "        return defin[0].upper() + defin[1:]\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Distance travelled per unit time'"
      ]
     },
     "execution_count": 1475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "define('speed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previously published clues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and if all else fails, just use a clue that's been previously published!\n",
    "# these are all from the NYT, so we know they're good quality :)\n",
    "\n",
    "def pull_clue(word, file='nytclues.pkl'):\n",
    "    import pickle\n",
    "    from random import randint\n",
    "    \n",
    "    with open(file, 'rb') as g:\n",
    "        cluedic = pickle.load(g)\n",
    "    \n",
    "    if word in cluedic:\n",
    "        \n",
    "        # a clue with '?' is a play on words, which is fun\n",
    "        # one of my goals is to be able to write code to generate my own puns\n",
    "        for x in cluedic[word]:\n",
    "            if '?' in x:\n",
    "                return x\n",
    "            \n",
    "        # if there's no punny clue for the word, let's just use a random one\n",
    "        try:\n",
    "            clue = randint(0, len(cluedic[word])-1)\n",
    "            return cluedic[word][clue]\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ravenous?'"
      ]
     },
     "execution_count": 1476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pull_clue('black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put all the clue functions together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1477,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clue(word):\n",
    "    \n",
    "    # this order works reasonably well, combined with the thresholds built into the individual functions\n",
    "    \n",
    "    if movie_clue(word):\n",
    "        return movie_clue(word)\n",
    "    \n",
    "    if idiom_clue(word):\n",
    "        return idiom_clue(word)\n",
    "    \n",
    "    if describe(word):\n",
    "        return describe(word)# + ' (RANDO DEF)'\n",
    "    \n",
    "    if find_seq(word):\n",
    "        return find_seq(word)\n",
    "    \n",
    "    if find_xyz(word):\n",
    "        return find_xyz(word)\n",
    "    \n",
    "    if synset(word):\n",
    "        return synset(word)# + ' (SYNSET)'\n",
    "    \n",
    "    if example(word):\n",
    "        return example(word)# + ' (EXAMPLE)'\n",
    "    \n",
    "    if synonyms(word):\n",
    "        return synonyms(word)# + ' (WORD2VEC)'\n",
    "    \n",
    "    if define(word):\n",
    "        return define(word)# + ' (DEFINITION)'\n",
    "    \n",
    "    if pull_clue(word):\n",
    "        return pull_clue(word)# + ' (PULLED)'\n",
    "    \n",
    "    # some words can't be clued yet\n",
    "    # but I'm working on it!\n",
    "    return word + \": Figure this out, Zoe...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Let's make a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1479,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makegrid(n=15):\n",
    "    \n",
    "    # empty grid\n",
    "    grid = [[' ']*n for i in range(n)]\n",
    "    \n",
    "    from random import randint\n",
    "    \n",
    "    # this function will find two valid squares to be shaded\n",
    "    def shade(n=n):\n",
    "        \n",
    "        # randomly pick a square\n",
    "        row = randint(0,(n+1)//2)\n",
    "        col = randint(0,n-1)\n",
    "        srow = n-row-1\n",
    "        scol = n-col-1\n",
    "        halfway = n+1//2\n",
    "        \n",
    "        # we can't pick a square that's already shaded\n",
    "        if grid[row][col] == '#':\n",
    "            return shade()\n",
    "        \n",
    "        # here's the second square (rotationally symmetric)\n",
    "        grid[srow][scol] = '#'\n",
    "        \n",
    "        # make sure this doesn't create a word shorter than three letters (per NYT rules)        \n",
    "        if ((row==1 and grid[0][col]==' ') or\n",
    "                (row==2 and (grid[1][col]==' ' or grid[0][col]==' ')) or\n",
    "                (row>2 and (grid[row-2][col]=='#' or grid[row-3][col]=='#'))):\n",
    "            grid[srow][scol] = ' '\n",
    "            return shade()\n",
    "        if grid[row+2][col]=='#' or grid[row+3][col]=='#':\n",
    "            grid[srow][scol] = ' '\n",
    "            return shade()\n",
    "        if ((col==1 and grid[row][0]==' ') or\n",
    "                (col==2 and (grid[row][1]==' ' or grid[row][0]==' ')) or\n",
    "                (col>2 and (grid[row][col-2]=='#' or grid[row][col-3]=='#'))):\n",
    "            grid[srow][scol] = ' '\n",
    "            return shade()\n",
    "        if ((col==n-2 and grid[row][n-1]==' ') or\n",
    "                (col==n-3 and (grid[row][n-2]==' ' or grid[row][n-1]==' ')) or\n",
    "                (col<n-3 and (grid[row][col+2]=='#' or grid[row][col+3]=='#'))):\n",
    "            grid[n-row-1][n-col-1] = ' '\n",
    "            return shade()\n",
    "        \n",
    "        # if everything works out, we can actually change it now\n",
    "        grid[row][col] = '#'\n",
    "        return\n",
    "\n",
    "    # generate the right number of shaded squares (proportional to size of grid)\n",
    "    for i in range(0, int((n**2)*.16//2)):\n",
    "        shade()\n",
    "        \n",
    "    grid = [''.join(i) for i in grid]\n",
    "    \n",
    "    save it!\n",
    "    with open('pattern1', 'w') as g:\n",
    "        g.write('\\n'.join(grid) + '\\n')\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1478,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['      #   #    ',\n",
       " '               ',\n",
       " '               ',\n",
       " '##       #     ',\n",
       " '#      #    ###',\n",
       " '      ##   #   ',\n",
       " '     #    ##   ',\n",
       " '    ##   ##    ',\n",
       " '   ##    #     ',\n",
       " '   #   ##      ',\n",
       " '###    #      #',\n",
       " '     #       ##',\n",
       " '               ',\n",
       " '               ',\n",
       " '    #   #      ']"
      ]
     },
     "execution_count": 1478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makegrid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fill the grid with words\n",
    "### (and get a list of the words used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makefill(grid=\"pattern6\", out=\"randompuzzle.txt\", dic=\"word-file\"):\n",
    "    \n",
    "    # create the fill using a grid (random by default) and a given dictionary\n",
    "    from subprocess import call\n",
    "\n",
    "    with open(out, 'w') as g:\n",
    "        call([\"./cword\", grid, dic], stdout=g)\n",
    "    \n",
    "    # now we read the fill\n",
    "    with open(out, 'r') as g:\n",
    "        fill = g.read()\n",
    "            \n",
    "    fill = fill.split('\\n')[:-1]\n",
    "    \n",
    "    # make csv for d3 purposes\n",
    "    numbers = ','.join([str(i) for i in range(len(grid))])\n",
    "    gridlines = []\n",
    "    for i in grid:\n",
    "        gridlines.append(','.join([j for j in i]))\n",
    "    gridlines = '\\n'.join(gridlines)\n",
    "    skeleton = numbers + '\\n' + gridlines\n",
    "\n",
    "    with open('randomskeleton.csv', 'w') as g:\n",
    "        g.write(skeleton)\n",
    "    \n",
    "    # these will be the lists of clues, but we have to work backwards from the fill\n",
    "    across = []\n",
    "    down = []\n",
    "    \n",
    "    # this is to make a grid for the js representation\n",
    "    jsgrid = []\n",
    "    \n",
    "    # go through and find out which squares should be numbered\n",
    "    counter = 0\n",
    "    for rnum, row in enumerate(fill):\n",
    "        for cnum, char in enumerate(row):\n",
    "            \n",
    "            if char=='#':\n",
    "                jsgrid.append('#')\n",
    "                continue\n",
    "            \n",
    "            # create appropriate numbering (the across and down list numbers must coordinate)\n",
    "            if cnum==0 or rnum==0 or row[cnum-1]=='#' or fill[rnum-1][cnum]=='#':\n",
    "                counter += 1\n",
    "                jsgrid.append(counter)\n",
    "                \n",
    "                # record each across word (with corresponding number)\n",
    "                if cnum==0 or row[cnum-1]=='#':\n",
    "                    acrossword = row[cnum:].split('#')[0]\n",
    "                    across.append((counter, acrossword))\n",
    "                \n",
    "                # record each down word (with corresponding number)\n",
    "                if rnum==0 or fill[rnum-1][cnum]=='#':\n",
    "                    downword = ' '.join(l[cnum] for l in fill[rnum:]).split('#')[0].replace(' ','')\n",
    "                    down.append((counter, downword))\n",
    "                    \n",
    "            if char!='#' and cnum!=0 and rnum!=0 and row[cnum-1]!='#' and fill[rnum-1][cnum]!='#':\n",
    "                jsgrid.append('')\n",
    "\n",
    "    \n",
    "    with open('randomfilllist.txt', 'w') as g:\n",
    "        filllist = ['Across:'] + ['%s. %s' % (i[0],i[1]) for i in across] + ['Down:'] + ['%s. %s' % (i[0],i[1]) for i in down]\n",
    "        g.write('\\n'.join(filllist))\n",
    "    \n",
    "    print([i for i in ''.join(fill)])\n",
    "#     print(jsgrid)\n",
    "    print(filllist)\n",
    "    return #filllist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'E', 'M', 'U', 'R', '#', 'A', 'C', 'I', 'D', '#', 'S', 'T', 'O', 'P', 'A', 'T', 'O', 'N', 'E', '#', 'C', 'O', 'M', 'A', '#', 'T', 'U', 'B', 'E', 'S', 'C', 'O', 'L', 'D', '#', 'H', 'I', 'P', 'S', '#', 'A', 'L', 'O', 'E', 'T', 'H', 'R', 'E', 'A', 'T', 'E', 'N', '#', 'H', 'O', 'L', 'L', 'E', 'R', '#', '#', '#', 'A', 'C', 'E', 'D', '#', 'R', 'I', 'M', 'L', 'E', 'S', 'S', 'C', 'H', 'A', 'S', 'T', 'E', '#', 'G', 'O', 'N', 'E', '#', '#', '#', '#', 'E', 'A', 'C', 'H', '#', 'S', 'T', 'R', 'U', 'G', 'G', 'L', 'I', 'N', 'G', 'N', 'I', 'N', 'E', 'S', '#', 'E', 'A', 'T', '#', 'A', 'U', 'D', 'I', 'O', 'T', 'R', 'E', 'S', 'P', 'A', 'S', 'S', 'E', 'S', '#', 'M', 'O', 'N', 'O', '#', '#', '#', '#', 'A', 'N', 'T', 'S', '#', 'T', 'A', 'B', 'L', 'E', 'D', 'S', 'O', 'N', 'A', 'T', 'A', 'S', '#', 'S', 'A', 'V', 'E', '#', '#', '#', 'C', 'L', 'O', 'V', 'E', 'R', '#', 'A', 'N', 'T', 'E', 'R', 'O', 'O', 'M', 'R', 'I', 'T', 'E', '#', 'C', 'L', 'U', 'E', '#', 'R', 'I', 'D', 'G', 'E', 'E', 'V', 'E', 'R', '#', 'H', 'I', 'R', 'E', '#', 'S', 'N', 'O', 'R', 'E', 'W', 'E', 'D', 'S', '#', 'Y', 'E', 'A', 'R', '#', 'E', 'G', 'R', 'E', 'T']\n",
      "[1, 2, 3, 4, 5, '#', 6, 7, 8, 9, '#', 10, 11, 12, 13, 14, '', '', '', '', '#', 15, '', '', '', '#', 16, '', '', '', 17, '', '', '', '', '#', 18, '', '', '', '#', 19, '', '', '', 20, '', '', '', '', 21, '', '', '#', 22, 23, '', '', '', '', '#', '#', '#', 24, '', '', '', '#', 25, '', '', '', '', '', '', 26, 27, 28, '', '', '', '#', 29, '', '', '', '#', '#', '#', '#', 30, '', '', '', '#', 31, 32, '', '', '', '', 33, 34, 35, 36, 37, '', '', '', 38, '#', 39, '', '', '#', 40, '', '', '', '', 41, '', '', '', '', 42, '', '', '', 43, '#', 44, '', '', '', '#', '#', '#', '#', 45, '', '', '', '#', 46, 47, '', '', '', '', 48, 49, 50, 51, '', '', '', '#', 52, '', '', '', '#', '#', '#', 53, '', '', '', '', '', '#', 54, '', '', '', '', 55, 56, 57, 58, '', '', '', '#', 59, 60, '', '', '#', 61, '', '', '', '', 62, '', '', '', '#', 63, '', '', '', '#', 64, '', '', '', '', 65, '', '', '', '#', 66, '', '', '', '#', 67, '', '', '', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Across:',\n",
       " '1. FEMUR',\n",
       " '6. ACID',\n",
       " '10. STOP',\n",
       " '14. ATONE',\n",
       " '15. COMA',\n",
       " '16. TUBE',\n",
       " '17. SCOLD',\n",
       " '18. HIPS',\n",
       " '19. ALOE',\n",
       " '20. THREATEN',\n",
       " '22. HOLLER',\n",
       " '24. ACED',\n",
       " '25. RIMLESS',\n",
       " '26. CHASTE',\n",
       " '29. GONE',\n",
       " '30. EACH',\n",
       " '31. STRUGGLING',\n",
       " '37. NINES',\n",
       " '39. EAT',\n",
       " '40. AUDIO',\n",
       " '41. TRESPASSES',\n",
       " '44. MONO',\n",
       " '45. ANTS',\n",
       " '46. TABLED',\n",
       " '48. SONATAS',\n",
       " '52. SAVE',\n",
       " '53. CLOVER',\n",
       " '54. ANTEROOM',\n",
       " '58. RITE',\n",
       " '59. CLUE',\n",
       " '61. RIDGE',\n",
       " '62. EVER',\n",
       " '63. HIRE',\n",
       " '64. SNORE',\n",
       " '65. WEDS',\n",
       " '66. YEAR',\n",
       " '67. EGRET',\n",
       " 'Down:',\n",
       " '1. FAST',\n",
       " '2. ETCH',\n",
       " '3. MOOR',\n",
       " '4. UNLEASHES',\n",
       " '5. REDACT',\n",
       " '6. ACHED',\n",
       " '7. COIN',\n",
       " '8. IMP',\n",
       " '9. DASHING',\n",
       " '10. STALL',\n",
       " '11. TULLE',\n",
       " '12. OBOES',\n",
       " '13. PEERS',\n",
       " '21. TEES',\n",
       " '23. OMEGA',\n",
       " '25. ROUTE',\n",
       " '26. CENT',\n",
       " '27. HAIR',\n",
       " '28. ACNE',\n",
       " '29. GRASS',\n",
       " '32. TESTS',\n",
       " '33. LUMBERING',\n",
       " '34. IDOL',\n",
       " '35. NINE',\n",
       " '36. GOOD',\n",
       " '38. SPATE',\n",
       " '42. ANARCHY',\n",
       " '43. STAT',\n",
       " '47. AVERSE',\n",
       " '48. SCREW',\n",
       " '49. OLIVE',\n",
       " '50. NOTED',\n",
       " '51. AVERS',\n",
       " '52. SNEER',\n",
       " '54. AURA',\n",
       " '55. ODOR',\n",
       " '56. OGRE',\n",
       " '57. MEET',\n",
       " '60. LIE']"
      ]
     },
     "execution_count": 1259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makefill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Clue the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cluefill(toclue='randomfilllist.txt'):\n",
    "    with open(toclue, 'r') as g:\n",
    "        clues = g.read().split('\\n')\n",
    "    \n",
    "    for ind, line in enumerate(clues):\n",
    "        if line == 'Across:' or line == 'Down:':\n",
    "            continue\n",
    "        \n",
    "        word = line.split('. ')[1]\n",
    "        clues[ind] = clues[ind].replace(word, clue(word.lower())) + '(%d letters)' % len(word)\n",
    "    \n",
    "    with open('randomclues.txt', 'w') as g:\n",
    "        g.write('\\n'.join(clues))\n",
    "    \n",
    "    return clues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Across:',\n",
       " '1. Shield, for example',\n",
       " '6. Type of shrub',\n",
       " '10. Like nudge or propel(synonyms)',\n",
       " '14. S(define)',\n",
       " '15. Type of examination',\n",
       " '16. \"__ the Wild\" (2007 movie)',\n",
       " '17. A(define)',\n",
       " '18. Pimple, for example',\n",
       " '19. Type of imitation',\n",
       " '20. Like draws or caters(synonyms)',\n",
       " '22. Betty Crocker offering(pull clue)',\n",
       " '24. A(define)',\n",
       " '25. A(define)',\n",
       " '26. United ___',\n",
       " '29. L(define)',\n",
       " '30. Dynamic start?(pull clue)',\n",
       " '31. Figure this out, Zoe...',\n",
       " '37. T(define)',\n",
       " '39. Type of noise',\n",
       " '40. S(define)',\n",
       " '41. F(define)',\n",
       " '44. Type of celebration',\n",
       " '45. Type of noisemaker',\n",
       " '46. Type of merchant',\n",
       " \"48. They're blue, in rhyme(pull clue)\",\n",
       " \"52. a person's appearance, manner, or demeanor(describe)\",\n",
       " '53. I(define)',\n",
       " '54. Like neuronal or prefrontal(synonyms)',\n",
       " '58. Type of writer',\n",
       " '59. Like oolong or coffees(synonyms)',\n",
       " '61. Type of gas',\n",
       " '62. Figure this out, Zoe...',\n",
       " '63. Like eyes or mouths(synonyms)',\n",
       " '64. A(define)',\n",
       " '65. Word with \"nothing\" or \"we’ve\"',\n",
       " '66. Guardianship, for example',\n",
       " '67. A(define)',\n",
       " 'Down:',\n",
       " '1. Heroine of Tennessee Williams\\'s \"Summer and Smoke\"(pull clue)',\n",
       " '2. an overwhelming defeat(describe)',\n",
       " '3. Type of dog',\n",
       " '4. Figure this out, Zoe...',\n",
       " '5. Type of selling',\n",
       " '6. A(define)',\n",
       " '7. Tolkien brutes(pull clue)',\n",
       " '8. \"Catch Me If You __\" (2002 movie)',\n",
       " '9. I(define)',\n",
       " '10. Figure this out, Zoe...',\n",
       " '11. Square(pull clue)',\n",
       " '12. Type of coccus',\n",
       " '13. C(define)',\n",
       " '21. Word with \"flow\" or \"market\"',\n",
       " '23. Like construct or install(synonyms)',\n",
       " '25. \"The Station __\" (2003 movie)',\n",
       " '26. Type of herb',\n",
       " '27. Type of drop',\n",
       " '28. an elaborate song for solo voice(describe)',\n",
       " '29. Type of bulb',\n",
       " '32. A(define)',\n",
       " '33. Figure this out, Zoe...',\n",
       " '34. U(define)',\n",
       " '35. Type of bundle',\n",
       " '36. \"__ Wars: Episode V - The Empire Strikes Back\" (1980 movie)',\n",
       " '38. A(define)',\n",
       " '42. T(define)',\n",
       " '43. Type of disturbance',\n",
       " '47. a quick reply to a question or remark(describe)',\n",
       " '48. lacking significance or liveliness or spirit or zest(describe)',\n",
       " '49. Figure this out, Zoe...',\n",
       " '50. Deep, for example',\n",
       " '51. Type of espresso',\n",
       " '52. Unlike a rolling stone?(pull clue)',\n",
       " '54. Type of wagon',\n",
       " '55. Type of artifact',\n",
       " '56. Type of stake',\n",
       " '57. Much ___',\n",
       " '60. Cannes dew?(pull clue)']"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluefill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Make a puzzle :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makepuzzle():\n",
    "    makegrid()\n",
    "    makefill()\n",
    "    return cluefill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S', 'P', 'E', 'C', 'K', '#', 'L', 'A', 'S', 'T', '#', 'S', 'C', 'A', 'B', 'A', 'L', 'T', 'A', 'R', '#', 'A', 'L', 'O', 'E', '#', 'T', 'A', 'C', 'O', 'M', 'A', 'C', 'R', 'O', '#', 'Y', 'A', 'W', 'N', '#', 'O', 'N', 'T', 'O', 'E', 'N', 'H', 'A', 'N', 'C', 'E', 'S', '#', 'U', 'P', 'R', 'O', 'O', 'T', '#', '#', '#', 'B', 'O', 'O', 'R', '#', 'C', 'O', 'O', 'K', 'E', 'R', 'Y', 'A', 'F', 'F', 'I', 'R', 'M', '#', 'S', 'O', 'U', 'S', '#', '#', '#', '#', 'C', 'L', 'A', 'N', '#', 'B', 'A', 'L', 'U', 'S', 'T', 'R', 'A', 'D', 'E', 'R', 'E', 'S', 'E', 'T', '#', 'G', 'U', 'N', '#', 'S', 'E', 'P', 'I', 'A', 'E', 'X', 'T', 'R', 'O', 'V', 'E', 'R', 'T', 'S', '#', 'F', 'E', 'N', 'S', '#', '#', '#', '#', 'T', 'A', 'N', 'S', '#', 'C', 'O', 'R', 'S', 'E', 'T', 'R', 'E', 'S', 'T', 'A', 'R', 'T', '#', 'F', 'A', 'R', 'E', '#', '#', '#', 'U', 'N', 'H', 'O', 'L', 'Y', '#', 'H', 'A', 'R', 'A', 'S', 'S', 'E', 'S', 'S', 'N', 'O', 'W', '#', 'I', 'D', 'O', 'L', '#', 'C', 'H', 'E', 'A', 'P', 'T', 'U', 'R', 'N', '#', 'N', 'A', 'P', 'S', '#', 'L', 'E', 'A', 'S', 'E', 'S', 'I', 'T', 'S', '#', 'G', 'L', 'E', 'E', '#', 'E', 'R', 'R', 'E', 'D']\n",
      "['Across:', '1. SPECK', '6. LAST', '10. SCAB', '14. ALTAR', '15. ALOE', '16. TACO', '17. MACRO', '18. YAWN', '19. ONTO', '20. ENHANCES', '22. UPROOT', '24. BOOR', '25. COOKERY', '26. AFFIRM', '29. SOUS', '30. CLAN', '31. BALUSTRADE', '37. RESET', '39. GUN', '40. SEPIA', '41. EXTROVERTS', '44. FENS', '45. TANS', '46. CORSET', '48. RESTART', '52. FARE', '53. UNHOLY', '54. HARASSES', '58. SNOW', '59. IDOL', '61. CHEAP', '62. TURN', '63. NAPS', '64. LEASE', '65. SITS', '66. GLEE', '67. ERRED', 'Down:', '1. SAME', '2. PLAN', '3. ETCH', '4. CARABINER', '5. KRONOR', '6. LAYER', '7. ALAS', '8. SOW', '9. TENUOUS', '10. STORK', '11. CANOE', '12. ACTOR', '13. BOOTY', '21. COMB', '23. POSTS', '25. COUNT', '26. ACRE', '27. FLEX', '28. FAST', '29. SLURS', '32. AGENT', '33. REFRESHER', '34. APES', '35. DINE', '36. EAST', '38. TOTAL', '42. VARYING', '43. SCAR', '47. ORACLE', '48. RUSTS', '49. ENNUI', '50. SHORT', '51. TOWNS', '52. FALSE', '54. HOPE', '55. SEAR', '56. EASE', '57. SPED', '60. DAL']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Across:',\n",
       " '1. Mote (SYNSET)(5 letters)',\n",
       " '6. \"Indiana Jones and the __ Crusade\" (1989 movie)(4 letters)',\n",
       " '10. Strikebreaker (SYNSET)(4 letters)',\n",
       " '14. Type of table (EXAMPLE)(5 letters)',\n",
       " '15. Found chiefly in Africa (DEFINITION)(4 letters)',\n",
       " '16. Type of mexican (EXAMPLE)(4 letters)',\n",
       " '17. Type of instruction (EXAMPLE)(5 letters)',\n",
       " '18. Gape (SYNSET)(4 letters)',\n",
       " '19. Word with \"hold\" or \"back\"(4 letters)',\n",
       " '20. Like strengthens or augments (WORD2VEC)(8 letters)',\n",
       " '22. Eradicate (SYNSET)(6 letters)',\n",
       " '24. Churl (SYNSET)(4 letters)',\n",
       " '25. The act of preparing something by the application of heat (DEFINITION)(7 letters)',\n",
       " '26. Confirm (SYNSET)(6 letters)',\n",
       " '29. Former French coins of low denominations (DEFINITION)(4 letters)',\n",
       " '30. Tribe (SYNSET)(4 letters)',\n",
       " '31. Handrail (SYNSET)(10 letters)',\n",
       " '37. Type of device (EXAMPLE)(5 letters)',\n",
       " '39. ___ violence(3 letters)',\n",
       " '40. Burnt sienna (SYNSET)(5 letters)',\n",
       " '41. People concerned more with practical realities than with inner thoughts and feelings (DEFINITION)(10 letters)',\n",
       " '44. Marsh (SYNSET)(4 letters)',\n",
       " '45. Sunburn (SYNSET)(4 letters)',\n",
       " '46. Girdle (SYNSET)(6 letters)',\n",
       " '48. Start an engine again, for example (DEFINITION)(7 letters)',\n",
       " '52. Proceed, get along, or succeed (RANDO DEF)(4 letters)',\n",
       " '53. Demonic (SYNSET)(6 letters)',\n",
       " '54. Like mistreats or terrorizes (WORD2VEC)(8 letters)',\n",
       " '58. \"__ White and the Seven Dwarfs\" (1937 movie)(4 letters)',\n",
       " '59. God (SYNSET)(4 letters)',\n",
       " '61. Inexpensive (SYNSET)(5 letters)',\n",
       " '62. Word with \"around\" or \"every\"(4 letters)',\n",
       " '63. Sleep (SYNSET)(4 letters)',\n",
       " '64. Rental (SYNSET)(5 letters)',\n",
       " '65. Like occupies or nestles (WORD2VEC)(4 letters)',\n",
       " '66. Hilarity (SYNSET)(4 letters)',\n",
       " '67. To make a mistake or be incorrect (DEFINITION)(5 letters)',\n",
       " 'Down:',\n",
       " '1. Type of european (EXAMPLE)(4 letters)',\n",
       " '2. ___ would(4 letters)',\n",
       " '3. Engrave (SYNSET)(4 letters)',\n",
       " '4. Karabiner (SYNSET)(9 letters)',\n",
       " '5. Swedish currency (PULLED)(6 letters)',\n",
       " '6. Single thickness of usually some homogeneous substance (DEFINITION)(5 letters)',\n",
       " '7. Unfortunately (SYNSET)(4 letters)',\n",
       " '8. Type of swine (EXAMPLE)(3 letters)',\n",
       " '9. Fragile (SYNSET)(7 letters)',\n",
       " '10. Large mostly Old World wading birds typically having white-and-black plumage (DEFINITION)(5 letters)',\n",
       " '11. Kayak, for one (EXAMPLE)(5 letters)',\n",
       " '12. Thespian (SYNSET)(5 letters)',\n",
       " '13. Loot (SYNSET)(5 letters)',\n",
       " '21. Type of device (EXAMPLE)(4 letters)',\n",
       " '23. Word with \"Twitter\" or \"media\"(5 letters)',\n",
       " '25. \"The __ of Monte Cristo\" (2002 movie)(5 letters)',\n",
       " '26. Unit of area used in English-speaking countries (DEFINITION)(4 letters)',\n",
       " '27. Show muscle? (PULLED)(4 letters)',\n",
       " '28. Word with \"enough\" or \"food\"(4 letters)',\n",
       " '29. Like epithets or insults (WORD2VEC)(5 letters)',\n",
       " '32. \"The Station __\" (2003 movie)(5 letters)',\n",
       " '33. Fee paid to counsel in a case that lasts more than one day (DEFINITION)(9 letters)',\n",
       " '34. \"Planet of the __\" (1968 movie)(4 letters)',\n",
       " '35. Have some fancy provisions? (PULLED)(4 letters)',\n",
       " '36. \"__ of Eden\" (1955 movie)(4 letters)',\n",
       " '38. \"__ Recall\" (1990 movie)(5 letters)',\n",
       " '42. Like differing (WORD2VEC)(7 letters)',\n",
       " '43. Mark left by the healing of injured tissue (DEFINITION)(4 letters)',\n",
       " '47. Seer (SYNSET)(6 letters)',\n",
       " '48. Corrode (SYNSET)(5 letters)',\n",
       " '49. Boredom (SYNSET)(5 letters)',\n",
       " '50. \"__ Term 12\" (2013 movie)(5 letters)',\n",
       " '51. Town (SYNSET)(5 letters)',\n",
       " '52. Fictitious (SYNSET)(5 letters)',\n",
       " '54. \"Star Wars: Episode IV - A New __\" (1977 movie)(4 letters)',\n",
       " '55. Char (SYNSET)(4 letters)',\n",
       " '56. Alleviate (SYNSET)(4 letters)',\n",
       " '57. Like drove or chased (WORD2VEC)(4 letters)',\n",
       " '60. Metric unit of volume or capacity equal to 10 liters (DEFINITION)(3 letters)']"
      ]
     },
     "execution_count": 1386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makepuzzle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
